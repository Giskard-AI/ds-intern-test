{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical exercise - Data scientist intern @ Giskard\n",
    "\n",
    "Hi! As part of our recruitment process, we’d like you to complete the following technical test in 10 days. Once you finish the exercise, you can send your notebook by email.\n",
    "\n",
    "If you have problems running the notebook, get in touch with Matteo at matteo@giskard.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Code review\n",
    "\n",
    "Your fellow intern is working on securing our API and wrote some code to generate secure tokens. You have been asked to review their code and make sure it is secure and robust. Can you spot the problem and write a short feedback?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ALPHABET = \"abcdefghijklmnopqrstuvxyz0123456789\"\n",
    "\n",
    "\n",
    "def generate_secret_key(size: int = 20):\n",
    "    \"\"\"Generates a cryptographically secure random token.\"\"\"\n",
    "    token = \"\".join(random.choice(ALPHABET) for _ in range(size))\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Bug hunting\n",
    "\n",
    "Our users reported some strange behaviour linked to the following code. Can you help track down the bug and fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_value(signal: list):\n",
    "    for i in range(len(signal)):\n",
    "        if signal[i] < 0:\n",
    "            signal[i] = -signal[i]\n",
    "\n",
    "    return signal\n",
    "\n",
    "\n",
    "signal = [1.2, -0.3, 4.7, 2.1, -0.1, -1.6, 0.1, 2.2, 0.5, -1.0]\n",
    "\n",
    "peak_amp = max(get_absolute_value(signal))\n",
    "peak_to_peak_amp = max(signal) - min(signal)\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "Signal characteristics\n",
    "======================\n",
    "Peak amplitude:\\t{peak_amp:.2f}\n",
    "Peak-to-peak:\\t{peak_to_peak_amp:.2f}\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Clusters\n",
    "\n",
    "Matteo, our ML researcher, is struggling with a dataset of 40-dimensional points. He’s sure there are some clusters in there, but he does not know how many. Can you help him find the correct number of clusters in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.load(\"points_1.npy\")\n",
    "\n",
    "# ...\n",
    "\n",
    "print(\"It looks like there are\", \"???\", \"clusters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Dimensions\n",
    "\n",
    "Matteo is grateful for how you helped him with the cluster finding, and he has another problem for you. He has another high-dimensional dataset, but he thinks that those points could be represented in a lower dimensional space. Can you help him determine how many dimensions would be enough to well represent the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.load(\"points_2.npy\")\n",
    "\n",
    "# ...\n",
    "\n",
    "print(\"It looks the data is\", \"???-dimensional\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Not bad reviews\n",
    "\n",
    "\n",
    "We trained a random forest model to predict if a film review is positive or negative. Here is the training code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Load training data\n",
    "train_data = datasets.load_dataset(\"sst2\", split=\"train[:20000]\").to_pandas()\n",
    "valid_data = datasets.load_dataset(\"sst2\", split=\"validation\").to_pandas()\n",
    "\n",
    "# Prepare model\n",
    "with open(\"stopwords.txt\", \"r\") as f:\n",
    "    stopwords = [w.strip() for w in f.readlines()]\n",
    "\n",
    "preprocessor = TfidfVectorizer(stop_words=stopwords, max_features=5000)\n",
    "classifier = RandomForestClassifier(n_estimators=400, n_jobs=-1)\n",
    "\n",
    "model = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", classifier)])\n",
    "\n",
    "# Train\n",
    "X = train_data.sentence\n",
    "y = train_data.label\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\n",
    "    \"Training complete.\",\n",
    "    \"Accuracy:\",\n",
    "    model.score(valid_data.sentence, valid_data.label),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it works quite well, but we noticed it has some problems with reviews containing negations, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels are:\n",
    "# 1 = Positive, 0 = Negative\n",
    "\n",
    "# this returns positive, that’s right!\n",
    "assert model.predict([\"This movie is good\"]) == [1]\n",
    "\n",
    "# negative! bingo!\n",
    "assert model.predict([\"This movie is bad\"]) == [0]\n",
    "\n",
    "# WHOOPS! this ↓ is predicted as negative?! uhm…\n",
    "assert model.predict([\"This movie is not bad at all!\"]) == [1]\n",
    "\n",
    "# WHOOPS! this ↓ is predicted as negative?! why?\n",
    "assert model.predict([\"This movie is not perfect, but very good!\"]) == [1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you help us understand what is going on? Do you have any idea on how to fix it?\n",
    "You can edit the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Mad GPT\n",
    "\n",
    "Matteo is a good guy but he is a bit messy: he fine-tuned a GPT-2 model, but it seems that something went wrong during the process and the model became obsessed with early Romantic literature.\n",
    "\n",
    "Could you check how the model would continue a sentence starting with “Ty”? Could you recover the logit of the next best token? And its probability?\n",
    "\n",
    "You can get the model from the HuggingFace Hub as `mattbit/gpt2wb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mattbit/gpt2wb\")\n",
    "\n",
    "# ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
